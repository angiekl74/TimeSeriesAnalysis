{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs = pd.read_excel(\"MapleBSCupHist.xlsx\", index_col=[0], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbs.head()\n",
    "type(mbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  686],\n",
       "       [   20],\n",
       "       [ 6830],\n",
       "       [14213],\n",
       "       [ 9400],\n",
       "       [10740],\n",
       "       [10290],\n",
       "       [ 8260],\n",
       "       [19456],\n",
       "       [ 9462],\n",
       "       [12899],\n",
       "       [13439],\n",
       "       [11509],\n",
       "       [12878],\n",
       "       [13967],\n",
       "       [19111],\n",
       "       [12164],\n",
       "       [ 8097],\n",
       "       [10525],\n",
       "       [10897],\n",
       "       [14392],\n",
       "       [15304],\n",
       "       [24049],\n",
       "       [19706],\n",
       "       [16909],\n",
       "       [17734],\n",
       "       [18601],\n",
       "       [18764],\n",
       "       [17659],\n",
       "       [16330],\n",
       "       [12646],\n",
       "       [16297],\n",
       "       [18601],\n",
       "       [18997],\n",
       "       [23166],\n",
       "       [21995],\n",
       "       [28056],\n",
       "       [34825],\n",
       "       [30823],\n",
       "       [44551],\n",
       "       [27123],\n",
       "       [ 8310],\n",
       "       [11779],\n",
       "       [13380],\n",
       "       [22498],\n",
       "       [32002],\n",
       "       [32410],\n",
       "       [30688],\n",
       "       [12943]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mbs.info\n",
    "mbs_series_value = mbs.values\n",
    "mbs_series_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMALIZATION TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOrmalization - Use this if \n",
    "# a) If you data is on different scales\n",
    "# b) Because some algorithms work better when data is normalized\n",
    "# c) As a data scientist, you should do this\n",
    "\n",
    "# Here's the formula for NORMALIZATION\n",
    "# normalization = (x-min)/(max-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbs_series_value.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbs_series_value.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01495587343648245"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So when we normalize the data, the first value of 686 is transformed to value 0.014955.  The value will always \n",
    "# within the value of 0-1.  In Sklearn library, the MixMaxScaler does this for you.\n",
    "\n",
    "(686-20)/(44551-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = scaler.fit(mbs_series_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.data_min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44551.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.data_max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs_normalize = scaler.transform(mbs_series_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01495587])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbs_normalize[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01495587]\n",
      "[0.]\n",
      "[0.15292717]\n",
      "[0.31872179]\n",
      "[0.21063978]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(mbs_normalize[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that the value is the same (0.0149558) when using sklearn data transformation technique using MinMaxScaler and transform AND doing it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01495587],\n",
       "       [0.        ],\n",
       "       [0.15292717],\n",
       "       [0.31872179],\n",
       "       [0.21063978],\n",
       "       [0.24073118],\n",
       "       [0.23062586],\n",
       "       [0.18503964],\n",
       "       [0.43645999],\n",
       "       [0.21203207],\n",
       "       [0.28921426],\n",
       "       [0.30134064],\n",
       "       [0.25800004],\n",
       "       [0.28874267],\n",
       "       [0.31319755],\n",
       "       [0.42871258],\n",
       "       [0.2727089 ],\n",
       "       [0.18137926],\n",
       "       [0.23590308],\n",
       "       [0.24425681],\n",
       "       [0.32274146],\n",
       "       [0.34322158],\n",
       "       [0.53960163],\n",
       "       [0.44207406],\n",
       "       [0.37926388],\n",
       "       [0.3977903 ],\n",
       "       [0.41725989],\n",
       "       [0.42092026],\n",
       "       [0.39610608],\n",
       "       [0.36626171],\n",
       "       [0.28353282],\n",
       "       [0.36552065],\n",
       "       [0.41725989],\n",
       "       [0.42615257],\n",
       "       [0.51977274],\n",
       "       [0.49347645],\n",
       "       [0.62958389],\n",
       "       [0.78159035],\n",
       "       [0.69172037],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that you have NORMALIZED the data, you can now do the same ARIMA techniques\n",
    "# a) Split normalized data into train & test sets\n",
    "# b) Create the model\n",
    "# c) Fit the model\n",
    "\n",
    "train_mbs = mbs_normalize[0:40]\n",
    "train_mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mbs = mbs_normalize[40:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60863219],\n",
       "       [0.18616245],\n",
       "       [0.26406324],\n",
       "       [0.30001572],\n",
       "       [0.50477196],\n",
       "       [0.71819631],\n",
       "       [0.72735847],\n",
       "       [0.68868878],\n",
       "       [0.29020233]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "# Create the model\n",
    "mbs_arimanormalize_model = ARIMA(train_mbs, order=(3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "mbs_arimanormalize_fit = mbs_arimanormalize_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-60.837199010832876"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check AIC\n",
    "mbs_arimanormalize_fit.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITHOUT normalizing, it was 774.0700534328645!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast cups using ARIMA model (2,1,2).  Give us the next 9 months.  Then you can compare to the TEST set\n",
    "cups_forecast = mbs_arimanormalize_fit.forecast(steps = 9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92080961, 0.97577212, 1.01463415, 0.98914647, 1.08032688,\n",
       "       1.03686126, 1.10925219, 1.11523407, 1.12137367])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cups_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60863219],\n",
       "       [0.18616245],\n",
       "       [0.26406324],\n",
       "       [0.30001572],\n",
       "       [0.50477196],\n",
       "       [0.71819631],\n",
       "       [0.72735847],\n",
       "       [0.68868878],\n",
       "       [0.29020233]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does cups_forecast compare to test set?\n",
    "test_mbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972749573162686"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "np.sqrt(mean_squared_error(test_mbs, cups_forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform cups_forecast back and test_mbs. We had to reshape the data first\n",
    "\n",
    "cups_forecast_reshape = cups_forecast.reshape(len(cups_forecast), 1)\n",
    "test_mbs_reshape = test_mbs.reshape(len(test_mbs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reshaping, we can REVERSE it \n",
    "cups_forecast_reverse = scaler.inverse_transform(cups_forecast_reshape)\n",
    "test_mbs_reverse = scaler.inverse_transform(test_mbs_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41024.5726564 ],\n",
       "       [43472.10829143],\n",
       "       [45202.67344832],\n",
       "       [44067.68145882],\n",
       "       [48128.03625622],\n",
       "       [46192.46875525],\n",
       "       [49416.10949221],\n",
       "       [49682.48822736],\n",
       "       [49955.89071812]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cups_forecast_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27123.],\n",
       "       [ 8310.],\n",
       "       [11779.],\n",
       "       [13380.],\n",
       "       [22498.],\n",
       "       [32002.],\n",
       "       [32410.],\n",
       "       [30688.],\n",
       "       [12943.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mbs_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22980.615525492125"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calc the error\n",
    "np.sqrt(mean_squared_error(test_mbs_reverse, cups_forecast_reverse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, this data transformation technique DID NOT work.  Sqrt error is still higher!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STANDARDIZATION TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-mean / standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data should be normally distributed.  If it is, this technique should work like a charm\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mbs_series_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler = std_scaler.fit(mbs_series_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17048.59183673])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75238271.30279051])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_mbs = std_scaler.transform(mbs_series_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.88639524])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_mbs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After you have transformed, you can now do\n",
    "# a) Split normalized data into train & test sets\n",
    "# b) Create the model\n",
    "# c) Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stdmbs = std_mbs[0:40]\n",
    "test_stdmbs = std_mbs[40:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "# Create the model\n",
    "mbs_arimaSTD_model = ARIMA(train_stdmbs, order=(3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "mbs_arimaSTD_model_fit = mbs_arimaSTD_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.75951252821253"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check AIC - it is higher than after we normalized!  But let's continue with the forecast\n",
    "mbs_arimaSTD_model_fit.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbs_arimaSTD_model_forecast = mbs_arimaSTD_model_fit.forecast(steps = 9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.76419939, 3.04635121, 3.24581355, 3.11508754, 3.58304925,\n",
       "       3.36004813, 3.73160474, 3.76234238, 3.79391806])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbs_arimaSTD_model_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.16144898],\n",
       "       [-1.00744663],\n",
       "       [-0.60751579],\n",
       "       [-0.4229412 ],\n",
       "       [ 0.62824629],\n",
       "       [ 1.72393459],\n",
       "       [ 1.77097171],\n",
       "       [ 1.57244738],\n",
       "       [-0.47332165]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the STD forecast compare to the test?\n",
    "test_stdmbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By looking at the 2 sets, looks like there is some variation.  Let's inverse and check the sqrt.\n",
    "# Let's reshape and reverse\n",
    "\n",
    "mbs_arimaSTDforecast_reshape = mbs_arimaSTD_model_forecast.reshape(len(mbs_arimaSTD_model_forecast), 1)\n",
    "test_STDmbs_reshape = test_stdmbs.reshape(len(test_stdmbs), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After reshaping, we can REVERSE it \n",
    "arimaSTD_forecast_reverse = std_scaler.inverse_transform(mbs_arimaSTDforecast_reshape)\n",
    "test_STDmbs_reverse = std_scaler.inverse_transform(test_STDmbs_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27123.],\n",
       "       [ 8310.],\n",
       "       [11779.],\n",
       "       [13380.],\n",
       "       [22498.],\n",
       "       [32002.],\n",
       "       [32410.],\n",
       "       [30688.],\n",
       "       [12943.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_STDmbs_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26597.856028563107"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calc the error\n",
    "np.sqrt(mean_squared_error(test_STDmbs_reverse, arimaSTD_forecast_reverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python37664bitpythondataconda4d5fd80126dc4277998df777cb4466d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
